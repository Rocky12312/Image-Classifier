{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPPVzMx6NiDG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ozzRlS4-V0Jt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd drive/My\\ Drive/image classifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9UVmCbr3aMMm",
        "colab_type": "text"
      },
      "source": [
        "changing the color space of the data from rgb to gray scale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcFoHbg4gCWj",
        "colab_type": "text"
      },
      "source": [
        "Converting the image such that we can use transfer learning to use pretrained model(vgg,alexnet and many others)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phrYfbJZZnAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGHR3pFxuCTJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For converting image from rgb to grayscale\n",
        "import cv2\n",
        "import os\n",
        "path = \"/content/drive/My Drive/image classifier/test/seg_test/seg_test/sea/\"\n",
        "path1 = \"/content/drive/My Drive/image classifier/test1/sea/\"\n",
        "for i in os.listdir(path):\n",
        "    img = cv2.imread(path+i)\n",
        "    col = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
        "    cv2.imwrite(os.path.join(path1,i),col)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5HR1VDNuItT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#For resizing the image\n",
        "import os\n",
        "import cv2\n",
        "path2 = \"/content/drive/My Drive/image classifier/test1/sea/\"\n",
        "path3 = \"/content/drive/My Drive/image classifier/test2/sea/\"\n",
        "for i in os.listdir(path2):\n",
        "    img = cv2.imread(path2+i)\n",
        "    dim = (224,224) \n",
        "    resized = cv2.resize(img, dim, interpolation = cv2.INTER_AREA) \n",
        "    cv2.imwrite(os.path.join(path3,i),resized)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l30cH6asaPDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Or use this for color changing and resizing\n",
        "path = \"/content/drive/My Drive/image classifier/test/seg_test/seg_test/sea/\"\n",
        "for i in os.listdir(path):\n",
        "  count = 0\n",
        "  image = cv2_imread(\"{}\".format(path+i))\n",
        "  image_gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
        "  image_gray_resized = cv2.resize(image_gray,(224,224),interpolation = cv2.INTER_AREA)\n",
        "  cv2.imwrite(os.path.join(\"/content/drive/My Drive/image classifier/test1/sea/\",\"{}.jpg\".format(count)),image_gray_resized)\n",
        "  count = count+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAviIgQuvjRR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_classes = 6\n",
        "img_rows, img_cols = 224,224\n",
        "batch_size = 200\n",
        "\n",
        "train_data_dir = '/content/drive/My Drive/image classifier/TRAIN/train2/'\n",
        "validation_data_dir = '/content/drive/My Drive/image classifier/TEST/test2/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH10iB96wXRz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 518
        },
        "outputId": "9ed4e316-a9cc-420b-8bf4-b99ed32c26cd"
      },
      "source": [
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Dropout,Flatten,BatchNormalization\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras.layers.advanced_activations import ELU\n",
        "from keras.layers.core import Activation, Flatten, Dropout, Dense\n",
        "from keras.optimizers import RMSprop, SGD, Adam\n",
        "from keras import regularizers\n",
        "from keras.regularizers import l1"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEnvyQZ9wMHv",
        "colab_type": "code",
        "outputId": "11005260-4895-4399-9df9-8802237355d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "      rotation_range=30,\n",
        "      shear_range=0.3,\n",
        "      zoom_range=0.3,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size=(224,224),\n",
        "        batch_size=batch_size,\n",
        "        color_mode=\"grayscale\",\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_generator = val_datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(224,224),\n",
        "        batch_size=batch_size,\n",
        "        color_mode=\"grayscale\",\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4019 images belonging to 6 classes.\n",
            "Found 1230 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V5GGg-wwbX2",
        "colab_type": "code",
        "outputId": "fec83ea9-b75f-46db-c2ff-2b0ea93c7e91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#For generating image data(use this or the upper block of code)\n",
        "\"\"\"import os\n",
        "from keras.preprocessing.image import ImageDataGenerator,array_to_img, img_to_array, load_img\n",
        "\n",
        "datagen = ImageDataGenerator( \n",
        "        rotation_range = 40, \n",
        "        shear_range = 0.4, \n",
        "        zoom_range = 0.3, \n",
        "        horizontal_flip = True, \n",
        "        brightness_range = (0.5, 1.5)) \n",
        "\n",
        "\n",
        "from PIL import Image\n",
        "a = [\"mountain\",\"buildings\",\"street\",\"forest\",\"glacier\",\"sea\"]\n",
        "for i in a:\n",
        "    dirs = os.listdir(\"/content/drive/My Drive/image classifier/TRAIN/train2/\"+i)\n",
        "    path = \"/content/drive/My Drive/image classifier/TRAIN/train2/\"+i\n",
        "    for item in dirs:\n",
        "        if item == \".DS_STORE\":\n",
        "            continue\n",
        "        if os.path.isfile(path+item):\n",
        "            img = Image.open(path+item)\n",
        "            x = img_to_array(img) \n",
        "            x = x.reshape(x.shape)   \n",
        "# using the above defined parameters.  \n",
        "            j = 0\n",
        "            for batch in datagen.flow(x, batch_size = 1, \n",
        "                          save_to_dir ='//content/drive/My Drive/image classifier/TRAIN/train3/'+i,  \n",
        "                          save_prefix ='image', save_format ='jpeg'):\n",
        "                j += 1\n",
        "                if j > 4:\n",
        "                    break\"\"\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'import os\\nfrom keras.preprocessing.image import ImageDataGenerator,array_to_img, img_to_array, load_img\\n\\ndatagen = ImageDataGenerator( \\n        rotation_range = 40, \\n        shear_range = 0.4, \\n        zoom_range = 0.3, \\n        horizontal_flip = True, \\n        brightness_range = (0.5, 1.5)) \\n\\n\\nfrom PIL import Image\\na = [\"mountain\",\"buildings\",\"street\",\"forest\",\"glacier\",\"sea\"]\\nfor i in a:\\n    dirs = os.listdir(\"/content/drive/My Drive/image classifier/TRAIN/train2/\"+i)\\n    path = \"/content/drive/My Drive/image classifier/TRAIN/train2/\"+i\\n    for item in dirs:\\n        if item == \".DS_STORE\":\\n            continue\\n        if os.path.isfile(path+item):\\n            img = Image.open(path+item)\\n            x = img_to_array(img) \\n            x = x.reshape(x.shape)   \\n# using the above defined parameters.  \\n            j = 0\\n            for batch in datagen.flow(x, batch_size = 1, \\n                          save_to_dir =\\'//content/drive/My Drive/image classifier/TRAIN/train3/\\'+i,  \\n                          save_prefix =\\'image\\', save_format =\\'jpeg\\'):\\n                j += 1\\n                if j > 4:\\n                    break'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCNRgykGxVWi",
        "colab_type": "code",
        "outputId": "d9e5488e-64ed-4e1e-ef3a-b3735d267ddd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(validation_generator.class_indices)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'buildings': 0, 'forest': 1, 'glacier': 2, 'mountain': 3, 'sea': 4, 'street': 5}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GyYGTCWExh6n",
        "colab_type": "text"
      },
      "source": [
        "Now either we can use some pretrained model or we can create our model(But to save our time lets use VGG16 pretrained weights)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWYFVA8Hx3SC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from keras.preprocessing import image\n",
        "from glob import glob"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwZW9GOz3QRM",
        "colab_type": "text"
      },
      "source": [
        "Downgraded my TensorFlow to version 1.14"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zINBrUMOAI3m",
        "colab_type": "text"
      },
      "source": [
        "This is the error which we basically get with using tensoflow 2.0-It looks like you are trying to use a version of multi-backend Keras that does not support TensorFlow 2.0. We recommend using `tf.keras`, or alternatively, downgrading to TensorFlow 1.14."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60ztBTAb3Bxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==1.14.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHUTrTZe0l3U",
        "colab_type": "code",
        "outputId": "cf66b7cd-d4c2-4ad7-db58-7b152aac2c1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "image_size = [224,224]\n",
        "vgg = VGG16(input_shape = image_size + [3],weights = \"/content/drive/My Drive/image classifier/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\",include_top = False)\n",
        "for layer in vgg.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OG1xuqr0wIy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folders = glob(\"/content/drive/My Drive/image classifier/TRAIN/train2/*\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "el64bl7q06sr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = Flatten()(vgg.output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMix8FY_09yR",
        "colab_type": "code",
        "outputId": "c5388907-4fb1-4b1f-e0e5-4c3732f8f868",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(len(folders))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVmtOrod1Cyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = Dense(len(folders),activation = \"softmax\")(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hA4F-Gf1Dm7",
        "colab_type": "code",
        "outputId": "67d42b26-188f-4c12-904a-a2f768b99dec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        }
      },
      "source": [
        "#Using vgg16 pretrained weights(only updating the parameters of last layer as we have only 6 outputs in final layer)\n",
        "from keras.models import Model\n",
        "model = Model(inputs = vgg.input,outputs =prediction)\n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 6)                 150534    \n",
            "=================================================================\n",
            "Total params: 14,865,222\n",
            "Trainable params: 150,534\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orHGzj-91GN1",
        "colab_type": "code",
        "outputId": "e39bdda7-bd92-4f97-b281-0c253befe330",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "model.compile(loss = \"categorical_crossentropy\",optimizer = \"adam\",metrics = [\"accuracy\"])"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VqT7y3jW1J3t",
        "colab_type": "code",
        "outputId": "c6cd0a11-4f07-4ce1-97e2-4faab759511b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./225,\n",
        "                                  zoom_range = 0.2,\n",
        "                                  shear_range = 0.2,\n",
        "                                  horizontal_flip = True)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_data_dir,\n",
        "        target_size = (224,224),\n",
        "        batch_size = 32,\n",
        "        class_mode = \"categorical\")\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        validation_data_dir,\n",
        "        target_size=(224,224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4019 images belonging to 6 classes.\n",
            "Found 1230 images belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6qf2Q6hEQMU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5ec3ed3-8d26-4ad3-ad3d-a6b9e2a3b12b"
      },
      "source": [
        "class_labels = validation_generator.class_indices\n",
        "class_labels = {v: k for k, v in class_labels.items()}\n",
        "print(class_labels)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 'buildings', 1: 'forest', 2: 'glacier', 3: 'mountain', 4: 'sea', 5: 'street'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EB53nXf1QRo",
        "colab_type": "code",
        "outputId": "fa01e48b-4b50-4f34-bb2d-a51ee8ff2484",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Can train more for more accuracy(We can basically train the model on more number of epochs to get higher accuracy)\n",
        "\"\"\"fit = model.fit_generator(train_generator,validation_data = test_generator,epochs = 10,steps_per_epoch=len(train_generator)/5,validation_steps = len(test_generator)/5)\n",
        "model.save(\"model.h1\")\"\"\""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'fit = model.fit_generator(train_generator,validation_data = test_generator,epochs = 10,steps_per_epoch=len(train_generator)/5,validation_steps = len(test_generator)/5)\\nmodel.save(\"model.h1\")'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PsvWUr4BS06",
        "colab_type": "code",
        "outputId": "e47569ee-9481-44b3-8194-3affe8c5393d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "#Loading the model weights\n",
        "model.load_weights(os.path.join(\"model.h1\"))\n",
        "\n",
        "from keras.models import load_model\n",
        "#Loading the model\n",
        "classifier = load_model('model.h1')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBQIZJ9jGpTv",
        "colab_type": "code",
        "outputId": "96a83f10-c28e-4e43-ff16-019d409d39a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Checking the output on a single image \n",
        "img = cv2.imread(\"20140.jpg\")\n",
        "image = cv2.resize(img,(224,224))\n",
        "\n",
        "from keras.preprocessing.image import img_to_array\n",
        "image = img_to_array(image)\n",
        "#4d input to model\n",
        "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "# prepare the image for the VGG model\n",
        "image = preprocess_input(image)\n",
        "\n",
        "img_class = classifier.predict(image)\n",
        "prediction = img_class[0]\n",
        "classname = img_class[0]\n",
        "print(\"Class: \",classname)\n",
        "#Giving the probablities of different classes "
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class:  [1. 0. 0. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgHhsMK0M6zu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Path to the image folder containing 18 images(on which we will be checking the output)\n",
        "path = \"/content/drive/My Drive/image classifier/images_for_prediction/\"\n",
        "#Keys are the original labels and value are the predicted labels(keys and value pairs are of dictionary)\n",
        "output = {}\n",
        "#Iterating through the folder of images\n",
        "for i in os.listdir(path):\n",
        "  image = cv2.imread(path+i)\n",
        "  image = cv2.resize(image,(224,224))\n",
        "  image = img_to_array(image)\n",
        "  image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "  #Preparing the image for VGG model\n",
        "  image = preprocess_input(image)\n",
        "  #Predicting probablity across all output classes\n",
        "  img_class = classifier.predict(image)\n",
        "  label = class_labels[img_class.argmax()]\n",
        "  output[i] = label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOxnpNVWQglH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "c79688b2-ced9-41cf-9092-93a73fe31f9c"
      },
      "source": [
        "print(output)\n",
        "print(len(output))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'building (2).jpg': 'buildings', '182.jpg': 'street', 'building.jpg': 'buildings', 'street (1).jpg': 'street', 'forest.jpg': 'forest', 'mountain (1).jpg': 'glacier', '271.jpg': 'glacier', 'street.jpg': 'street', 'building (3).jpg': 'buildings', 'forest (2).jpg': 'sea', 'building (4).jpg': 'buildings', 'sea.jpg': 'sea', 'mountain.jpg': 'sea', '252.jpg': 'sea', 'building (1).jpg': 'buildings', 'forest (1).jpg': 'forest', 'glacier.jpg': 'glacier', '185.jpg': 'glacier'}\n",
            "18\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}